{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, cross_val_score, train_test_split, RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Modelos del Zoo\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, HuberRegressor, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Nuevos modelos de boosting\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from src.utils import LoadData\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DIRECTORIO_SALIDA = \"../modelos_ajustados\"\n",
    "os.makedirs(DIRECTORIO_SALIDA, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T16:24:02.783419Z",
     "start_time": "2026-02-25T16:24:02.776349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model_pool(random_state=42):\n",
    "    \"\"\"\n",
    "    Pool de modelos con regularizaci√≥n ULTRA-CONSERVADORA\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'ExtraTrees': ExtraTreesRegressor(\n",
    "            n_estimators=30,\n",
    "            max_depth=6,\n",
    "            min_samples_leaf=30,\n",
    "            min_samples_split=60,\n",
    "            max_features=0.5,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "\n",
    "        'RandomForest': RandomForestRegressor(\n",
    "            n_estimators=30,\n",
    "            max_depth=6,\n",
    "            min_samples_leaf=30,\n",
    "            min_samples_split=60,\n",
    "            max_features=0.5,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "\n",
    "        'DT-Simple': DecisionTreeRegressor(\n",
    "            max_depth=3,\n",
    "            min_samples_leaf=30,\n",
    "            min_samples_split=60,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "\n",
    "        'Ridge': make_pipeline(\n",
    "            StandardScaler(),\n",
    "            Ridge(alpha=1.0)\n",
    "        ),\n",
    "\n",
    "        'KNN': make_pipeline(\n",
    "            StandardScaler(),\n",
    "            KNeighborsRegressor(\n",
    "                n_neighbors=9,\n",
    "                weights='distance',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        # XGBoost con regularizaci√≥n MUY CONSERVADORA\n",
    "        'XGBoost': XGBRegressor(\n",
    "            n_estimators=60,\n",
    "            max_depth=3,\n",
    "            min_child_weight=15,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=2.0,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "            verbosity=0\n",
    "        ),\n",
    "\n",
    "        # LightGBM con regularizaci√≥n MUY CONSERVADORA\n",
    "        'LightGBM': LGBMRegressor(\n",
    "            n_estimators=60,\n",
    "            max_depth=3,\n",
    "            num_leaves=7,\n",
    "            min_child_samples=35,\n",
    "            learning_rate=0.05,\n",
    "            feature_fraction=0.7,\n",
    "            bagging_fraction=0.7,\n",
    "            bagging_freq=5,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=2.0,\n",
    "            min_gain_to_split=0.05,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "            verbose=-1,\n",
    "            force_col_wise=True\n",
    "        ),\n",
    "\n",
    "        # ElasticNet\n",
    "        'ElasticNet': make_pipeline(\n",
    "            StandardScaler(),\n",
    "            ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=2000)\n",
    "        )\n",
    "    }"
   ],
   "id": "bcf1c6c99ad3aec9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n        # XGBoost con regularizaci√≥n MUY CONSERVADORA\\n        'XGBoost': XGBRegressor(\\n            n_estimators=60,\\n            max_depth=3,\\n            min_child_weight=15,\\n            learning_rate=0.05,\\n            subsample=0.7,\\n            colsample_bytree=0.7,\\n            reg_alpha=0.5,\\n            reg_lambda=2.0,\\n            n_jobs=-1,\\n            random_state=random_state,\\n            verbosity=0\\n        ),\\n\\n        # LightGBM con regularizaci√≥n MUY CONSERVADORA\\n        'LightGBM': LGBMRegressor(\\n            n_estimators=60,\\n            max_depth=3,\\n            num_leaves=7,\\n            min_child_samples=35,\\n            learning_rate=0.05,\\n            feature_fraction=0.7,\\n            bagging_fraction=0.7,\\n            bagging_freq=5,\\n            reg_alpha=0.5,\\n            reg_lambda=2.0,\\n            min_gain_to_split=0.05,\\n            n_jobs=-1,\\n            random_state=random_state,\\n            verbose=-1,\\n            force_col_wise=True\\n        ),\\n\\n        # ElasticNet\\n        'ElasticNet': make_pipeline(\\n            StandardScaler(),\\n            ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=2000)\\n        )\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T16:24:02.796435Z",
     "start_time": "2026-02-25T16:24:02.789546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_param_grid(nombre_modelo, n_samples, n_features):\n",
    "    \"\"\"\n",
    "    Grids de hiperpar√°metros ADAPTATIVOS seg√∫n tama√±o y dimensi√≥n del dataset\n",
    "    Regularizaci√≥n m√°s agresiva en datasets peque√±os\n",
    "    \"\"\"\n",
    "    # Clasificaci√≥n del dataset\n",
    "    is_small = n_samples < 500\n",
    "    is_medium = 500 <= n_samples < 2000\n",
    "    is_high_dim = n_features > 50\n",
    "\n",
    "    # KNN: m√≠nimo 5 vecinos, m√°ximo razonable\n",
    "    max_k = min(31, max(9, int(np.sqrt(n_samples))))\n",
    "\n",
    "    grids = {\n",
    "\n",
    "        'ExtraTrees': {\n",
    "            'n_estimators': [20, 30, 50],\n",
    "            'max_depth': (\n",
    "                [3, 4, 5] if is_small else      # MUY bajo para peque√±os\n",
    "                [4, 5, 6] if is_medium else\n",
    "                [5, 6, 8]\n",
    "            ),\n",
    "            'min_samples_leaf': (\n",
    "                [30, 40, 50] if is_small else\n",
    "                [25, 30, 35] if is_medium else\n",
    "                [20, 25, 30]\n",
    "            ),\n",
    "            'min_samples_split': (\n",
    "                [60, 80, 100] if is_small else\n",
    "                [50, 60, 70] if is_medium else\n",
    "                [40, 50, 60]\n",
    "            ),\n",
    "            'max_features': [0.3, 0.5, 0.7]\n",
    "        },\n",
    "\n",
    "        'RandomForest': {\n",
    "            'n_estimators': [20, 30, 50],\n",
    "            'max_depth': (\n",
    "                [3, 4, 5] if is_small else\n",
    "                [4, 5, 6] if is_medium else\n",
    "                [5, 6, 8]\n",
    "            ),\n",
    "            'min_samples_leaf': (\n",
    "                [30, 40, 50] if is_small else\n",
    "                [25, 30, 35] if is_medium else\n",
    "                [20, 25, 30]\n",
    "            ),\n",
    "            'min_samples_split': (\n",
    "                [60, 80, 100] if is_small else\n",
    "                [50, 60, 70] if is_medium else\n",
    "                [40, 50, 60]\n",
    "            ),\n",
    "            'max_features': [0.3, 0.5, 0.7]\n",
    "        },\n",
    "\n",
    "        'DT-Simple': {\n",
    "            'max_depth': (\n",
    "                [2, 3, 4] if is_small else\n",
    "                [3, 4, 5] if is_medium else\n",
    "                [4, 5, 6]\n",
    "            ),\n",
    "            'min_samples_leaf': (\n",
    "                [30, 40, 50] if is_small else\n",
    "                [25, 30, 35] if is_medium else\n",
    "                [20, 25, 30]\n",
    "            ),\n",
    "            'min_samples_split': (\n",
    "                [60, 80, 100] if is_small else\n",
    "                [50, 60, 70] if is_medium else\n",
    "                [40, 50, 60]\n",
    "            )\n",
    "        },\n",
    "\n",
    "        # Pipeline: StandardScaler + Ridge\n",
    "        'Ridge': {\n",
    "            'ridge__alpha': np.logspace(-3, 2, 25).tolist() # Antes empezaba en -2\n",
    "        },\n",
    "\n",
    "        # Pipeline: StandardScaler + KNN\n",
    "        'KNN': {\n",
    "            'kneighborsregressor__n_neighbors': list(range(5, max_k + 1, 2)),\n",
    "            'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "            'kneighborsregressor__p': [1, 2]\n",
    "        },\n",
    "\n",
    "        # XGBoost - Con penalizaci√≥n extra para datasets problem√°ticos\n",
    "        'XGBoost': {\n",
    "            'n_estimators': [40, 60, 80],\n",
    "            'max_depth': (\n",
    "                [2] if is_small else                    # SOLO depth=2 para boston\n",
    "                [3, 4] if is_medium else\n",
    "                [4, 5]\n",
    "            ),\n",
    "            'min_child_weight': (\n",
    "                [15, 20, 25] if is_small else           # M√ÅS restrictivo para boston\n",
    "                [8, 12, 15] if (is_medium and is_high_dim) else  # us_crime\n",
    "                [5, 10] if is_medium else\n",
    "                [3, 5]\n",
    "            ),\n",
    "            'learning_rate': (\n",
    "                [0.01, 0.03] if is_small else           # Solo LR bajo para boston\n",
    "                [0.02, 0.03, 0.05] if is_high_dim else  # us_crime\n",
    "                [0.03, 0.05, 0.08]\n",
    "            ),\n",
    "            'subsample': [0.6, 0.7, 0.8],\n",
    "            'colsample_bytree': (\n",
    "                [0.4, 0.5] if is_high_dim else          # us_crime: solo 40-50% features\n",
    "                [0.5, 0.6, 0.7]\n",
    "            ),\n",
    "            'reg_alpha': (\n",
    "                [1.0, 2.0, 4.0] if (is_small or is_high_dim) else  # Regularizaci√≥n extrema\n",
    "                [0.1, 0.5, 1.0]\n",
    "            ),\n",
    "            'reg_lambda': (\n",
    "                [2.0, 4.0, 6.0] if (is_small or is_high_dim) else\n",
    "                [1.0, 2.0, 4.0]\n",
    "            )\n",
    "        },\n",
    "\n",
    "        # LightGBM - Similar ajuste\n",
    "        'LightGBM': {\n",
    "            'n_estimators': [40, 60, 80],\n",
    "            'max_depth': (\n",
    "                [2] if is_small else\n",
    "                [3, 4] if is_medium else\n",
    "                [4, 5]\n",
    "            ),\n",
    "            'num_leaves': (\n",
    "                [3, 5] if is_small else                 # Menos hojas para boston\n",
    "                [5, 7] if is_high_dim else              # us_crime\n",
    "                [7, 10, 15] if is_medium else\n",
    "                [15, 20, 25]\n",
    "            ),\n",
    "            'min_child_samples': (\n",
    "                [30, 40, 50] if is_small else           # M√°s muestras para boston\n",
    "                [25, 35] if (is_medium and is_high_dim) else  # us_crime\n",
    "                [20, 25] if is_medium else\n",
    "                [15, 20]\n",
    "            ),\n",
    "            'learning_rate': (\n",
    "                [0.01, 0.03] if is_small else\n",
    "                [0.02, 0.03, 0.05] if is_high_dim else\n",
    "                [0.03, 0.05, 0.08]\n",
    "            ),\n",
    "            'feature_fraction': (\n",
    "                [0.3, 0.4, 0.5] if is_high_dim else     # us_crime: m√°ximo 50%\n",
    "                [0.5, 0.6, 0.7]\n",
    "            ),\n",
    "            'bagging_fraction': [0.6, 0.7, 0.8],\n",
    "            'bagging_freq': [3, 5],\n",
    "            'reg_alpha': (\n",
    "                [1.0, 2.0] if (is_small or is_high_dim) else\n",
    "                [0.1, 0.5, 1.0]\n",
    "            ),\n",
    "            'reg_lambda': (\n",
    "                [2.0, 4.0] if (is_small or is_high_dim) else\n",
    "                [1.0, 2.0, 4.0]\n",
    "            )\n",
    "        },\n",
    "\n",
    "        # Pipeline: StandardScaler + ElasticNet (Corregimos Underfitting)\n",
    "        'ElasticNet': {\n",
    "            'elasticnet__alpha': np.logspace(-4, 1, 25).tolist(), # Valores mucho m√°s bajos para permitir ajuste real\n",
    "            'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return grids.get(nombre_modelo, {})"
   ],
   "id": "e6c1b51b1971b7e3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T16:24:02.821170Z",
     "start_time": "2026-02-25T16:24:02.808773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calcular_correlacion_errores(errores_dict):\n",
    "    \"\"\"\n",
    "    Calcula la correlaci√≥n entre errores de pares de modelos.\n",
    "    Valores bajos indican diversidad.\n",
    "    \"\"\"\n",
    "    nombres = list(errores_dict.keys())\n",
    "    n = len(nombres)\n",
    "    correlaciones = np.zeros((n, n))\n",
    "\n",
    "    for i, m1 in enumerate(nombres):\n",
    "        for j, m2 in enumerate(nombres):\n",
    "            if i == j:\n",
    "                correlaciones[i, j] = 1.0\n",
    "            else:\n",
    "                corr = np.corrcoef(errores_dict[m1], errores_dict[m2])[0, 1]\n",
    "                correlaciones[i, j] = corr\n",
    "\n",
    "    return pd.DataFrame(correlaciones, index=nombres, columns=nombres)\n",
    "\n",
    "\n",
    "def procesar_dataset_oraculo(X, y, dataset_name):\n",
    "    \"\"\"\n",
    "    Nested CV con evaluaci√≥n independiente en test set\n",
    "    Repeated CV para datasets peque√±os\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üîµ PROCESANDO DATASET: {dataset_name} | Shape: {X.shape}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    is_small_dataset = n_samples < 500\n",
    "\n",
    "    # ===============================\n",
    "    # SPLIT INICIAL: Train/Test\n",
    "    # ===============================\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"üìä Split: Train={X_train_full.shape[0]} | Test={X_test.shape[0]}\")\n",
    "\n",
    "    # ===============================\n",
    "    # CV STRATEGY: Repeated CV para datasets peque√±os\n",
    "    # ===============================\n",
    "    if is_small_dataset:\n",
    "        n_splits = 3\n",
    "        n_repeats = 3\n",
    "        cv_inner = RepeatedKFold(\n",
    "            n_splits=n_splits,\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"üîÅ CV Strategy: Repeated {n_splits}-Fold x{n_repeats} (dataset peque√±o, reduce varianza)\")\n",
    "    else:\n",
    "        n_splits = 5\n",
    "        cv_inner = KFold(\n",
    "            n_splits=n_splits,\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"üîÅ CV Strategy: {n_splits}-Fold CV\")\n",
    "\n",
    "    pool_inicial = get_model_pool()\n",
    "    nombres_pool = list(pool_inicial.keys())\n",
    "\n",
    "    n_iter_map = {\n",
    "        'ExtraTrees': 30,\n",
    "        'RandomForest': 30,\n",
    "        'DT-Simple': 18,\n",
    "        'Ridge': 25,\n",
    "        'KNN': 25,\n",
    "        'XGBoost': 25,\n",
    "        'LightGBM': 25,\n",
    "        'ElasticNet': 25\n",
    "    }\n",
    "\n",
    "    modelos_ajustados_todos = {}\n",
    "    preds_oof_todos = {}\n",
    "    diagnostico_general = {}\n",
    "    cv_std_dict = {}  # Nueva m√©trica\n",
    "\n",
    "    print(f\"\\n1Ô∏è‚É£ Ajustando hiperpar√°metros (Inner CV)...\")\n",
    "\n",
    "    for name in nombres_pool:\n",
    "\n",
    "        base_model = get_model_pool()[name]\n",
    "        param_grid = get_param_grid(name, X_train_full.shape[0], n_features)\n",
    "        n_iter_modelo = n_iter_map.get(name, 20)\n",
    "\n",
    "        print(f\"\\n   -> Ajustando {name} (n_iter={n_iter_modelo})...\")\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            base_model,\n",
    "            param_grid,\n",
    "            n_iter=n_iter_modelo,\n",
    "            cv=cv_inner,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            refit=True,\n",
    "            return_train_score=True  # Para diagn√≥stico\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            search.fit(X_train_full, y_train_full)\n",
    "            best_model = search.best_estimator_\n",
    "\n",
    "            # ===============================\n",
    "            # C√ÅLCULO OOF (sobre train_full)\n",
    "            # ===============================\n",
    "            oof_preds = cross_val_predict(\n",
    "                best_model, X_train_full, y_train_full,\n",
    "                cv=cv_inner,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            rmse_oof = np.sqrt(mean_squared_error(y_train_full, oof_preds))\n",
    "\n",
    "            # ===============================\n",
    "            # DIAGN√ìSTICO OVERFIT (mejorado)\n",
    "            # ===============================\n",
    "            cv_scores_train = -search.cv_results_['mean_train_score'][search.best_index_]\n",
    "            cv_scores_test = -search.cv_results_['mean_test_score'][search.best_index_]\n",
    "            cv_std_test = search.cv_results_['std_test_score'][search.best_index_]\n",
    "\n",
    "            gap_ratio = cv_scores_test / cv_scores_train if cv_scores_train > 0 else 1.0\n",
    "\n",
    "            # Diagn√≥stico m√°s sofisticado\n",
    "            if name == 'KNN':\n",
    "                diagnostico = \"‚ö™ KNN (train score no informativo)\"\n",
    "            elif gap_ratio > 1.25:\n",
    "                diagnostico = \"üî¥ OVERFITTING\"\n",
    "            elif gap_ratio > 1.10:\n",
    "                diagnostico = \"üü° LEVE OVERFITTING\"\n",
    "            elif gap_ratio < 1.05 and cv_scores_test > np.median(list(diagnostico_general.values()) or [cv_scores_test]):\n",
    "                diagnostico = \"üîµ POSIBLE UNDERFITTING\"\n",
    "            else:\n",
    "                diagnostico = \"üü¢ AJUSTE SALUDABLE\"\n",
    "\n",
    "            print(f\"      RMSE Train (CV): {cv_scores_train:.4f}\")\n",
    "            print(f\"      RMSE Valid (CV): {cv_scores_test:.4f} ¬± {cv_std_test:.4f}\")\n",
    "            print(f\"      RMSE OOF      : {rmse_oof:.4f}\")\n",
    "            print(f\"      Gap Ratio     : {gap_ratio:.3f}\")\n",
    "            print(f\"      Diagn√≥stico   : {diagnostico}\")\n",
    "\n",
    "            modelos_ajustados_todos[name] = best_model\n",
    "            preds_oof_todos[name] = oof_preds\n",
    "            diagnostico_general[name] = cv_scores_test\n",
    "            cv_std_dict[name] = cv_std_test\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Fallo ajustando {name}: {e}\")\n",
    "\n",
    "    if len(modelos_ajustados_todos) < 3:\n",
    "        print(\"‚ö†Ô∏è No hay suficientes modelos ajustados para formar tr√≠o.\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\n2Ô∏è‚É£ Analizando diversidad de modelos (correlaci√≥n de errores)...\")\n",
    "\n",
    "    sq_errors_dict = {}\n",
    "    rmse_dict = {}\n",
    "\n",
    "    for name in modelos_ajustados_todos:\n",
    "        sq_errors_dict[name] = (y_train_full - preds_oof_todos[name])**2\n",
    "        rmse_dict[name] = np.sqrt(np.mean(sq_errors_dict[name]))\n",
    "\n",
    "    # Nueva m√©trica: correlaci√≥n entre errores\n",
    "    errores_dict = {name: y_train_full - preds_oof_todos[name] for name in modelos_ajustados_todos}\n",
    "    df_correlaciones = calcular_correlacion_errores(errores_dict)\n",
    "\n",
    "    print(\"\\n   üìâ Correlaci√≥n entre errores (valores bajos = m√°s diversidad):\")\n",
    "    print(df_correlaciones.round(3))\n",
    "\n",
    "    best_single_name = min(rmse_dict, key=rmse_dict.get)\n",
    "    best_single_rmse = rmse_dict[best_single_name]\n",
    "\n",
    "    print(f\"\\n   üèÜ Mejor Individual (OOF): {best_single_name} (RMSE: {best_single_rmse:.4f})\")\n",
    "\n",
    "    print(\"\\n3Ô∏è‚É£ Buscando el Dream Team (Or√°culo sobre OOF)...\")\n",
    "\n",
    "    # EL OR√ÅCULO ANCLADO: Obligamos a que el mejor especialista individual est√© en el tr√≠o\n",
    "    modelos_restantes = [m for m in modelos_ajustados_todos.keys() if m != best_single_name]\n",
    "    pares = list(itertools.combinations(modelos_restantes, 2))\n",
    "    trios = [(best_single_name, p[0], p[1]) for p in pares]\n",
    "    trio_results = []\n",
    "\n",
    "    for trio in trios:\n",
    "        m1, m2, m3 = trio\n",
    "\n",
    "        trio_sq_errors = np.column_stack((\n",
    "            sq_errors_dict[m1],\n",
    "            sq_errors_dict[m2],\n",
    "            sq_errors_dict[m3]\n",
    "        ))\n",
    "\n",
    "        min_sq_errors = np.min(trio_sq_errors, axis=1)\n",
    "        oracle_rmse = np.sqrt(np.mean(min_sq_errors))\n",
    "        improvement = 100 * (1 - oracle_rmse / best_single_rmse)\n",
    "\n",
    "        # Diversidad del tr√≠o (correlaci√≥n promedio entre sus errores)\n",
    "        corr_trio = [\n",
    "            df_correlaciones.loc[m1, m2],\n",
    "            df_correlaciones.loc[m1, m3],\n",
    "            df_correlaciones.loc[m2, m3]\n",
    "        ]\n",
    "        diversidad_promedio = np.mean(corr_trio)\n",
    "\n",
    "        trio_results.append({\n",
    "            'Trio': trio,\n",
    "            'Oracle_RMSE': oracle_rmse,\n",
    "            'Mejora_%': improvement,\n",
    "            'Diversidad_Avg_Corr': diversidad_promedio\n",
    "        })\n",
    "\n",
    "    df_trio = pd.DataFrame(trio_results).sort_values('Oracle_RMSE')\n",
    "\n",
    "    dream_team_names = df_trio.iloc[0]['Trio']\n",
    "    mejor_oracle_rmse = df_trio.iloc[0]['Oracle_RMSE']\n",
    "    mejora_teorica = df_trio.iloc[0]['Mejora_%']\n",
    "    diversidad_tr√≠o = df_trio.iloc[0]['Diversidad_Avg_Corr']\n",
    "\n",
    "    print(f\"   ‚ú® Dream Team: {dream_team_names}\")\n",
    "    print(f\"   üîÆ Mejora Te√≥rica (OOF): {mejora_teorica:.2f}%\")\n",
    "    print(f\"   üé≤ Diversidad (Corr Promedio): {diversidad_tr√≠o:.3f}\")\n",
    "\n",
    "    # ===============================\n",
    "    # VALIDACI√ìN INDEPENDIENTE (TEST)\n",
    "    # ===============================\n",
    "    print(\"\\n4Ô∏è‚É£ Evaluaci√≥n independiente en Test Set...\")\n",
    "\n",
    "    modelos_finales = [modelos_ajustados_todos[name] for name in dream_team_names]\n",
    "\n",
    "    # Predicciones individuales en test\n",
    "    preds_test = {}\n",
    "    rmse_test_individual = {}\n",
    "\n",
    "    for name in dream_team_names:\n",
    "        pred_test = modelos_ajustados_todos[name].predict(X_test)\n",
    "        preds_test[name] = pred_test\n",
    "        rmse_test_individual[name] = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "\n",
    "    # Mejor individual en test\n",
    "    best_test_name = min(rmse_test_individual, key=rmse_test_individual.get)\n",
    "    best_test_rmse = rmse_test_individual[best_test_name]\n",
    "\n",
    "    # Oracle en test (cota superior te√≥rica)\n",
    "    trio_sq_errors_test = np.column_stack([\n",
    "        (y_test - preds_test[name])**2 for name in dream_team_names\n",
    "    ])\n",
    "    min_sq_errors_test = np.min(trio_sq_errors_test, axis=1)\n",
    "    oracle_rmse_test = np.sqrt(np.mean(min_sq_errors_test))\n",
    "    mejora_real_test = 100 * (1 - oracle_rmse_test / best_test_rmse)\n",
    "\n",
    "    print(f\"   üß™ Mejor Individual (Test): {best_test_name} -> RMSE = {best_test_rmse:.4f}\")\n",
    "    print(f\"   üß™ Oracle Score (Test)   : RMSE = {oracle_rmse_test:.4f}\")\n",
    "    print(f\"   üìà Mejora Real (Test)    : {mejora_real_test:.2f}%\")\n",
    "\n",
    "    # ===============================\n",
    "    # GUARDADO\n",
    "    # ===============================\n",
    "    ruta_archivo = f\"{DIRECTORIO_SALIDA}/{dataset_name}_best_models.pkl\"\n",
    "\n",
    "    datos_a_guardar = {\n",
    "        'modelos': modelos_finales,\n",
    "        'nombres': dream_team_names,\n",
    "        'oracle_rmse_oof': mejor_oracle_rmse,\n",
    "        'oracle_rmse_test': oracle_rmse_test,\n",
    "        'mejora_teorica_oof': mejora_teorica,\n",
    "        'mejora_real_test': mejora_real_test,\n",
    "        'diversidad': diversidad_tr√≠o,\n",
    "        'correlaciones': df_correlaciones,\n",
    "        'cv_std': cv_std_dict\n",
    "    }\n",
    "\n",
    "    joblib.dump(datos_a_guardar, ruta_archivo)\n",
    "\n",
    "    print(f\"\\n   ‚úÖ Dream Team guardado en: {ruta_archivo}\")\n",
    "\n",
    "    return {\n",
    "        'Dataset': dataset_name,\n",
    "        'N_samples': n_samples,\n",
    "        'N_features': n_features,\n",
    "        'CV_Strategy': f\"Repeated {n_splits}x{n_repeats}\" if is_small_dataset else f\"{n_splits}-Fold\",\n",
    "        'Mejor_Individual_OOF': best_single_name,\n",
    "        'RMSE_Individual_OOF': best_single_rmse,\n",
    "        'Dream_Team': \" + \".join(dream_team_names),\n",
    "        'Oracle_RMSE_OOF': mejor_oracle_rmse,\n",
    "        'Mejora_Teorica_OOF_%': mejora_teorica,\n",
    "        'Oracle_RMSE_Test': oracle_rmse_test,\n",
    "        'Mejora_Real_Test_%': mejora_real_test,\n",
    "        'Diversidad_Avg_Corr': diversidad_tr√≠o,\n",
    "        'CV_Std_Promedio': np.mean(list(cv_std_dict.values()))\n",
    "    }"
   ],
   "id": "17418159b6909cfe",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T16:24:48.408820Z",
     "start_time": "2026-02-25T16:24:03.718027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "archivos_datasets = glob.glob(\"../data/regression/*.arff\")\n",
    "resultados_globales = []\n",
    "\n",
    "if not archivos_datasets:\n",
    "    print(\"¬°Ojo! No se han encontrado archivos .arff.\")\n",
    "else:\n",
    "    for ruta in tqdm(archivos_datasets, desc=\"Procesando datasets\"):\n",
    "        nombre_ds = os.path.basename(ruta).replace('.arff', '')\n",
    "        X, y = LoadData(ruta)\n",
    "\n",
    "        if X is not None:\n",
    "            # Asegurar compatibilidad estricta de memoria para Numpy/C++\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X = np.ascontiguousarray(X.values, dtype=np.float64)\n",
    "            y = np.ascontiguousarray(y, dtype=np.float64)\n",
    "\n",
    "            # Ejecutar y acumular el dict resultante\n",
    "            metricas_dataset = procesar_dataset_oraculo(X, y, nombre_ds)\n",
    "\n",
    "            if metricas_dataset is not None:\n",
    "                resultados_globales.append(metricas_dataset)\n",
    "\n",
    "    # 5. Guardar CSV resumen (Fuera del bucle for, pero dentro del else)\n",
    "    if resultados_globales:\n",
    "        df_resumen = pd.DataFrame(resultados_globales)\n",
    "        ruta_csv = os.path.join(DIRECTORIO_SALIDA, \"resumen_dream_teams.csv\")\n",
    "        df_resumen.to_csv(ruta_csv, index=False)\n",
    "        print(f\"\\nüìä Ejecuci√≥n finalizada. Resumen global guardado en: {ruta_csv}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìã RESUMEN FINAL:\")\n",
    "        print(\"=\"*80)\n",
    "        print(df_resumen.to_string(index=False))\n"
   ],
   "id": "b44af2b33a0b5d44",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando datasets:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîµ PROCESANDO DATASET: abalone | Shape: (4177, 7)\n",
      "============================================================\n",
      "üìä Split: Train=3341 | Test=836\n",
      "üîÅ CV Strategy: 5-Fold CV\n",
      "\n",
      "1Ô∏è‚É£ Ajustando hiperpar√°metros (Inner CV)...\n",
      "\n",
      "   -> Ajustando ExtraTrees (n_iter=30)...\n",
      "      RMSE Train (CV): 2.2812\n",
      "      RMSE Valid (CV): 2.3276 ¬± 0.0742\n",
      "      RMSE OOF      : 2.3288\n",
      "      Gap Ratio     : 1.020\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando RandomForest (n_iter=30)...\n",
      "      RMSE Train (CV): 2.0162\n",
      "      RMSE Valid (CV): 2.1770 ¬± 0.0753\n",
      "      RMSE OOF      : 2.1783\n",
      "      Gap Ratio     : 1.080\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando DT-Simple (n_iter=18)...\n",
      "      RMSE Train (CV): 2.1088\n",
      "      RMSE Valid (CV): 2.2907 ¬± 0.0794\n",
      "      RMSE OOF      : 2.2921\n",
      "      Gap Ratio     : 1.086\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando Ridge (n_iter=25)...\n",
      "      RMSE Train (CV): 2.2042\n",
      "      RMSE Valid (CV): 2.2523 ¬± 0.0870\n",
      "      RMSE OOF      : 2.2540\n",
      "      Gap Ratio     : 1.022\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando KNN (n_iter=25)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando datasets:  20%|‚ñà‚ñà        | 1/5 [00:06<00:24,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE Train (CV): -0.0000\n",
      "      RMSE Valid (CV): 2.1960 ¬± 0.0859\n",
      "      RMSE OOF      : 2.1977\n",
      "      Gap Ratio     : 1.000\n",
      "      Diagn√≥stico   : ‚ö™ KNN (train score no informativo)\n",
      "\n",
      "2Ô∏è‚É£ Analizando diversidad de modelos (correlaci√≥n de errores)...\n",
      "\n",
      "   üìâ Correlaci√≥n entre errores (valores bajos = m√°s diversidad):\n",
      "              ExtraTrees  RandomForest  DT-Simple  Ridge    KNN\n",
      "ExtraTrees         1.000         0.958      0.893  0.883  0.954\n",
      "RandomForest       0.958         1.000      0.948  0.900  0.969\n",
      "DT-Simple          0.893         0.948      1.000  0.855  0.906\n",
      "Ridge              0.883         0.900      0.855  1.000  0.891\n",
      "KNN                0.954         0.969      0.906  0.891  1.000\n",
      "\n",
      "   üèÜ Mejor Individual (OOF): RandomForest (RMSE: 2.1783)\n",
      "\n",
      "3Ô∏è‚É£ Buscando el Dream Team (Or√°culo sobre OOF)...\n",
      "   ‚ú® Dream Team: ('RandomForest', 'DT-Simple', 'Ridge')\n",
      "   üîÆ Mejora Te√≥rica (OOF): 16.75%\n",
      "   üé≤ Diversidad (Corr Promedio): 0.901\n",
      "\n",
      "4Ô∏è‚É£ Evaluaci√≥n independiente en Test Set...\n",
      "   üß™ Mejor Individual (Test): Ridge -> RMSE = 2.2485\n",
      "   üß™ Oracle Score (Test)   : RMSE = 1.8510\n",
      "   üìà Mejora Real (Test)    : 17.68%\n",
      "\n",
      "   ‚úÖ Dream Team guardado en: ../modelos_ajustados/abalone_best_models.pkl\n",
      "\n",
      "============================================================\n",
      "üîµ PROCESANDO DATASET: boston | Shape: (506, 13)\n",
      "============================================================\n",
      "üìä Split: Train=404 | Test=102\n",
      "üîÅ CV Strategy: 5-Fold CV\n",
      "\n",
      "1Ô∏è‚É£ Ajustando hiperpar√°metros (Inner CV)...\n",
      "\n",
      "   -> Ajustando ExtraTrees (n_iter=30)...\n",
      "      RMSE Train (CV): 6.3324\n",
      "      RMSE Valid (CV): 6.4462 ¬± 1.0468\n",
      "      RMSE OOF      : 6.5340\n",
      "      Gap Ratio     : 1.018\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando RandomForest (n_iter=30)...\n",
      "      RMSE Train (CV): 4.8594\n",
      "      RMSE Valid (CV): 5.2014 ¬± 0.8528\n",
      "      RMSE OOF      : 5.2737\n",
      "      Gap Ratio     : 1.070\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando DT-Simple (n_iter=18)...\n",
      "      RMSE Train (CV): 4.7713\n",
      "      RMSE Valid (CV): 5.5400 ¬± 0.5319\n",
      "      RMSE OOF      : 5.5665\n",
      "      Gap Ratio     : 1.161\n",
      "      Diagn√≥stico   : üü° LEVE OVERFITTING\n",
      "\n",
      "   -> Ajustando Ridge (n_iter=25)...\n",
      "      RMSE Train (CV): 4.6231\n",
      "      RMSE Valid (CV): 4.8583 ¬± 0.8340\n",
      "      RMSE OOF      : 4.9324\n",
      "      Gap Ratio     : 1.051\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando KNN (n_iter=25)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando datasets:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:08<00:11,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE Train (CV): -0.0000\n",
      "      RMSE Valid (CV): 4.5849 ¬± 1.1345\n",
      "      RMSE OOF      : 4.7271\n",
      "      Gap Ratio     : 1.000\n",
      "      Diagn√≥stico   : ‚ö™ KNN (train score no informativo)\n",
      "\n",
      "2Ô∏è‚É£ Analizando diversidad de modelos (correlaci√≥n de errores)...\n",
      "\n",
      "   üìâ Correlaci√≥n entre errores (valores bajos = m√°s diversidad):\n",
      "              ExtraTrees  RandomForest  DT-Simple  Ridge    KNN\n",
      "ExtraTrees         1.000         0.911      0.668  0.685  0.771\n",
      "RandomForest       0.911         1.000      0.830  0.725  0.746\n",
      "DT-Simple          0.668         0.830      1.000  0.588  0.585\n",
      "Ridge              0.685         0.725      0.588  1.000  0.726\n",
      "KNN                0.771         0.746      0.585  0.726  1.000\n",
      "\n",
      "   üèÜ Mejor Individual (OOF): KNN (RMSE: 4.7271)\n",
      "\n",
      "3Ô∏è‚É£ Buscando el Dream Team (Or√°culo sobre OOF)...\n",
      "   ‚ú® Dream Team: ('KNN', 'DT-Simple', 'Ridge')\n",
      "   üîÆ Mejora Te√≥rica (OOF): 25.61%\n",
      "   üé≤ Diversidad (Corr Promedio): 0.633\n",
      "\n",
      "4Ô∏è‚É£ Evaluaci√≥n independiente en Test Set...\n",
      "   üß™ Mejor Individual (Test): KNN -> RMSE = 4.4750\n",
      "   üß™ Oracle Score (Test)   : RMSE = 3.1733\n",
      "   üìà Mejora Real (Test)    : 29.09%\n",
      "\n",
      "   ‚úÖ Dream Team guardado en: ../modelos_ajustados/boston_best_models.pkl\n",
      "\n",
      "============================================================\n",
      "üîµ PROCESANDO DATASET: concrete | Shape: (1030, 8)\n",
      "============================================================\n",
      "üìä Split: Train=824 | Test=206\n",
      "üîÅ CV Strategy: 5-Fold CV\n",
      "\n",
      "1Ô∏è‚É£ Ajustando hiperpar√°metros (Inner CV)...\n",
      "\n",
      "   -> Ajustando ExtraTrees (n_iter=30)...\n",
      "      RMSE Train (CV): 10.1918\n",
      "      RMSE Valid (CV): 10.5662 ¬± 0.3266\n",
      "      RMSE OOF      : 10.5719\n",
      "      Gap Ratio     : 1.037\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando RandomForest (n_iter=30)...\n",
      "      RMSE Train (CV): 7.9742\n",
      "      RMSE Valid (CV): 8.5442 ¬± 0.4377\n",
      "      RMSE OOF      : 8.5563\n",
      "      Gap Ratio     : 1.071\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando DT-Simple (n_iter=18)...\n",
      "      RMSE Train (CV): 8.4323\n",
      "      RMSE Valid (CV): 9.3590 ¬± 0.8700\n",
      "      RMSE OOF      : 9.4004\n",
      "      Gap Ratio     : 1.110\n",
      "      Diagn√≥stico   : üü° LEVE OVERFITTING\n",
      "\n",
      "   -> Ajustando Ridge (n_iter=25)...\n",
      "      RMSE Train (CV): 10.5056\n",
      "      RMSE Valid (CV): 10.6277 ¬± 0.4762\n",
      "      RMSE OOF      : 10.6391\n",
      "      Gap Ratio     : 1.012\n",
      "      Diagn√≥stico   : üîµ POSIBLE UNDERFITTING\n",
      "\n",
      "   -> Ajustando KNN (n_iter=25)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando datasets:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:11<00:06,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE Train (CV): 0.6101\n",
      "      RMSE Valid (CV): 8.3760 ¬± 0.6768\n",
      "      RMSE OOF      : 8.4039\n",
      "      Gap Ratio     : 13.729\n",
      "      Diagn√≥stico   : ‚ö™ KNN (train score no informativo)\n",
      "\n",
      "2Ô∏è‚É£ Analizando diversidad de modelos (correlaci√≥n de errores)...\n",
      "\n",
      "   üìâ Correlaci√≥n entre errores (valores bajos = m√°s diversidad):\n",
      "              ExtraTrees  RandomForest  DT-Simple  Ridge    KNN\n",
      "ExtraTrees         1.000         0.860      0.629  0.753  0.655\n",
      "RandomForest       0.860         1.000      0.823  0.609  0.551\n",
      "DT-Simple          0.629         0.823      1.000  0.433  0.381\n",
      "Ridge              0.753         0.609      0.433  1.000  0.620\n",
      "KNN                0.655         0.551      0.381  0.620  1.000\n",
      "\n",
      "   üèÜ Mejor Individual (OOF): KNN (RMSE: 8.4039)\n",
      "\n",
      "3Ô∏è‚É£ Buscando el Dream Team (Or√°culo sobre OOF)...\n",
      "   ‚ú® Dream Team: ('KNN', 'DT-Simple', 'Ridge')\n",
      "   üîÆ Mejora Te√≥rica (OOF): 44.54%\n",
      "   üé≤ Diversidad (Corr Promedio): 0.478\n",
      "\n",
      "4Ô∏è‚É£ Evaluaci√≥n independiente en Test Set...\n",
      "   üß™ Mejor Individual (Test): KNN -> RMSE = 7.6024\n",
      "   üß™ Oracle Score (Test)   : RMSE = 4.6708\n",
      "   üìà Mejora Real (Test)    : 38.56%\n",
      "\n",
      "   ‚úÖ Dream Team guardado en: ../modelos_ajustados/concrete_best_models.pkl\n",
      "\n",
      "============================================================\n",
      "üîµ PROCESANDO DATASET: elevators | Shape: (16599, 18)\n",
      "============================================================\n",
      "üìä Split: Train=13279 | Test=3320\n",
      "üîÅ CV Strategy: 5-Fold CV\n",
      "\n",
      "1Ô∏è‚É£ Ajustando hiperpar√°metros (Inner CV)...\n",
      "\n",
      "   -> Ajustando ExtraTrees (n_iter=30)...\n",
      "      RMSE Train (CV): 0.0040\n",
      "      RMSE Valid (CV): 0.0041 ¬± 0.0000\n",
      "      RMSE OOF      : 0.0041\n",
      "      Gap Ratio     : 1.022\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando RandomForest (n_iter=30)...\n",
      "      RMSE Train (CV): 0.0033\n",
      "      RMSE Valid (CV): 0.0035 ¬± 0.0000\n",
      "      RMSE OOF      : 0.0035\n",
      "      Gap Ratio     : 1.065\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando DT-Simple (n_iter=18)...\n",
      "      RMSE Train (CV): 0.0039\n",
      "      RMSE Valid (CV): 0.0041 ¬± 0.0000\n",
      "      RMSE OOF      : 0.0041\n",
      "      Gap Ratio     : 1.059\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando Ridge (n_iter=25)...\n",
      "      RMSE Train (CV): 0.0029\n",
      "      RMSE Valid (CV): 0.0029 ¬± 0.0001\n",
      "      RMSE OOF      : 0.0029\n",
      "      Gap Ratio     : 1.002\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando KNN (n_iter=25)...\n",
      "      RMSE Train (CV): -0.0000\n",
      "      RMSE Valid (CV): 0.0037 ¬± 0.0001\n",
      "      RMSE OOF      : 0.0037\n",
      "      Gap Ratio     : 1.000\n",
      "      Diagn√≥stico   : ‚ö™ KNN (train score no informativo)\n",
      "\n",
      "2Ô∏è‚É£ Analizando diversidad de modelos (correlaci√≥n de errores)...\n",
      "\n",
      "   üìâ Correlaci√≥n entre errores (valores bajos = m√°s diversidad):\n",
      "              ExtraTrees  RandomForest  DT-Simple  Ridge    KNN\n",
      "ExtraTrees         1.000         0.935      0.799  0.719  0.887\n",
      "RandomForest       0.935         1.000      0.867  0.703  0.855\n",
      "DT-Simple          0.799         0.867      1.000  0.604  0.731\n",
      "Ridge              0.719         0.703      0.604  1.000  0.700\n",
      "KNN                0.887         0.855      0.731  0.700  1.000\n",
      "\n",
      "   üèÜ Mejor Individual (OOF): Ridge (RMSE: 0.0029)\n",
      "\n",
      "3Ô∏è‚É£ Buscando el Dream Team (Or√°culo sobre OOF)...\n",
      "   ‚ú® Dream Team: ('Ridge', 'DT-Simple', 'KNN')\n",
      "   üîÆ Mejora Te√≥rica (OOF): 25.92%\n",
      "   üé≤ Diversidad (Corr Promedio): 0.678\n",
      "\n",
      "4Ô∏è‚É£ Evaluaci√≥n independiente en Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando datasets:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:36<00:12, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üß™ Mejor Individual (Test): Ridge -> RMSE = 0.0028\n",
      "   üß™ Oracle Score (Test)   : RMSE = 0.0021\n",
      "   üìà Mejora Real (Test)    : 25.20%\n",
      "\n",
      "   ‚úÖ Dream Team guardado en: ../modelos_ajustados/elevators_best_models.pkl\n",
      "\n",
      "============================================================\n",
      "üîµ PROCESANDO DATASET: us_crime | Shape: (1994, 126)\n",
      "============================================================\n",
      "üìä Split: Train=1595 | Test=399\n",
      "üîÅ CV Strategy: 5-Fold CV\n",
      "\n",
      "1Ô∏è‚É£ Ajustando hiperpar√°metros (Inner CV)...\n",
      "\n",
      "   -> Ajustando ExtraTrees (n_iter=30)...\n",
      "      RMSE Train (CV): 0.1318\n",
      "      RMSE Valid (CV): 0.1415 ¬± 0.0090\n",
      "      RMSE OOF      : 0.1418\n",
      "      Gap Ratio     : 1.074\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando RandomForest (n_iter=30)...\n",
      "      RMSE Train (CV): 0.1257\n",
      "      RMSE Valid (CV): 0.1398 ¬± 0.0092\n",
      "      RMSE OOF      : 0.1401\n",
      "      Gap Ratio     : 1.112\n",
      "      Diagn√≥stico   : üü° LEVE OVERFITTING\n",
      "\n",
      "   -> Ajustando DT-Simple (n_iter=18)...\n",
      "      RMSE Train (CV): 0.1330\n",
      "      RMSE Valid (CV): 0.1525 ¬± 0.0093\n",
      "      RMSE OOF      : 0.1528\n",
      "      Gap Ratio     : 1.147\n",
      "      Diagn√≥stico   : üü° LEVE OVERFITTING\n",
      "\n",
      "   -> Ajustando Ridge (n_iter=25)...\n",
      "      RMSE Train (CV): 0.1275\n",
      "      RMSE Valid (CV): 0.1381 ¬± 0.0067\n",
      "      RMSE OOF      : 0.1382\n",
      "      Gap Ratio     : 1.083\n",
      "      Diagn√≥stico   : üü¢ AJUSTE SALUDABLE\n",
      "\n",
      "   -> Ajustando KNN (n_iter=25)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando datasets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:44<00:00,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE Train (CV): -0.0000\n",
      "      RMSE Valid (CV): 0.1469 ¬± 0.0070\n",
      "      RMSE OOF      : 0.1471\n",
      "      Gap Ratio     : 1.000\n",
      "      Diagn√≥stico   : ‚ö™ KNN (train score no informativo)\n",
      "\n",
      "2Ô∏è‚É£ Analizando diversidad de modelos (correlaci√≥n de errores)...\n",
      "\n",
      "   üìâ Correlaci√≥n entre errores (valores bajos = m√°s diversidad):\n",
      "              ExtraTrees  RandomForest  DT-Simple  Ridge    KNN\n",
      "ExtraTrees         1.000         0.988      0.884  0.906  0.898\n",
      "RandomForest       0.988         1.000      0.886  0.904  0.898\n",
      "DT-Simple          0.884         0.886      1.000  0.820  0.802\n",
      "Ridge              0.906         0.904      0.820  1.000  0.851\n",
      "KNN                0.898         0.898      0.802  0.851  1.000\n",
      "\n",
      "   üèÜ Mejor Individual (OOF): Ridge (RMSE: 0.1382)\n",
      "\n",
      "3Ô∏è‚É£ Buscando el Dream Team (Or√°culo sobre OOF)...\n",
      "   ‚ú® Dream Team: ('Ridge', 'DT-Simple', 'KNN')\n",
      "   üîÆ Mejora Te√≥rica (OOF): 24.33%\n",
      "   üé≤ Diversidad (Corr Promedio): 0.824\n",
      "\n",
      "4Ô∏è‚É£ Evaluaci√≥n independiente en Test Set...\n",
      "   üß™ Mejor Individual (Test): Ridge -> RMSE = 0.1340\n",
      "   üß™ Oracle Score (Test)   : RMSE = 0.0993\n",
      "   üìà Mejora Real (Test)    : 25.87%\n",
      "\n",
      "   ‚úÖ Dream Team guardado en: ../modelos_ajustados/us_crime_best_models.pkl\n",
      "\n",
      "üìä Ejecuci√≥n finalizada. Resumen global guardado en: ../modelos_ajustados\\resumen_dream_teams.csv\n",
      "\n",
      "================================================================================\n",
      "üìã RESUMEN FINAL:\n",
      "================================================================================\n",
      "  Dataset  N_samples  N_features CV_Strategy Mejor_Individual_OOF  RMSE_Individual_OOF                       Dream_Team  Oracle_RMSE_OOF  Mejora_Teorica_OOF_%  Oracle_RMSE_Test  Mejora_Real_Test_%  Diversidad_Avg_Corr  CV_Std_Promedio\n",
      "  abalone       4177           7      5-Fold         RandomForest             2.178338 RandomForest + DT-Simple + Ridge         1.813508             16.748076          1.850970           17.678048             0.900945         0.080366\n",
      "   boston        506          13      5-Fold                  KNN             4.727073          KNN + DT-Simple + Ridge         3.516637             25.606457          3.173260           29.089293             0.632813         0.880027\n",
      " concrete       1030           8      5-Fold                  KNN             8.403934          KNN + DT-Simple + Ridge         4.660411             44.544888          4.670772           38.562256             0.477965         0.557446\n",
      "elevators      16599          18      5-Fold                Ridge             0.002930          Ridge + DT-Simple + KNN         0.002170             25.916391          0.002103           25.196490             0.678083         0.000040\n",
      " us_crime       1994         126      5-Fold                Ridge             0.138243          Ridge + DT-Simple + KNN         0.104610             24.328659          0.099315           25.872315             0.824078         0.008232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
